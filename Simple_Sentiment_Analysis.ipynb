{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HtLjFToIEi_b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the IMDb dataset\n",
        "vocab_size = 10000  # Limit to the top 10,000 words\n",
        "max_len = 300  # Maximum length of review (in words)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
        "\n",
        "# Pad sequences to ensure uniform input size\n",
        "x_train = pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = pad_sequences(x_test, maxlen=max_len)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuVMyiB7Elxi",
        "outputId": "fe0f670a-8502-4085-9029-e244b2e0df23"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "5DjGibHLE6zC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xoo1QqgQE_GA",
        "outputId": "2abf4d29-4332-41d5-ff15-5bfc080f559a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "313/313 [==============================] - 34s 95ms/step - loss: 0.4330 - accuracy: 0.7986 - val_loss: 0.3239 - val_accuracy: 0.8716\n",
            "Epoch 2/5\n",
            "313/313 [==============================] - 17s 54ms/step - loss: 0.2404 - accuracy: 0.9068 - val_loss: 0.3031 - val_accuracy: 0.8750\n",
            "Epoch 3/5\n",
            "313/313 [==============================] - 12s 40ms/step - loss: 0.1669 - accuracy: 0.9383 - val_loss: 0.3614 - val_accuracy: 0.8612\n",
            "Epoch 4/5\n",
            "313/313 [==============================] - 10s 33ms/step - loss: 0.1123 - accuracy: 0.9610 - val_loss: 0.3951 - val_accuracy: 0.8628\n",
            "Epoch 5/5\n",
            "313/313 [==============================] - 10s 32ms/step - loss: 0.1106 - accuracy: 0.9603 - val_loss: 0.4450 - val_accuracy: 0.8390\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79f07da0b790>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test Accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RLYriZNFBnn",
        "outputId": "09ae1d97-4712-450d-9dc1-8cab8de911de"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4597 - accuracy: 0.8336\n",
            "Test Accuracy: 0.8335999846458435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_test)\n",
        "# Convert predictions to binary labels\n",
        "predicted_labels = (predictions > 0.5).astype(int)\n",
        "\n",
        "# Display some predictions\n",
        "for i in range(5):\n",
        "    print(f'Review: {x_test[i]}')\n",
        "    print(f'Prediction: {\"Positive\" if predicted_labels[i][0] == 1 else \"Negative\"}')\n",
        "    print(f'Actual: {\"Positive\" if y_test[i] == 1 else \"Negative\"}\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RSYHVliFY1q",
        "outputId": "a2d8c395-2150-4f7b-f11c-8c4e14f08a22"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 7s 8ms/step\n",
            "Review: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    1  591  202   14   31    6\n",
            "  717   10   10    2    2    5    4  360    7    4  177 5760  394  354\n",
            "    4  123    9 1035 1035 1035   10   10   13   92  124   89  488 7944\n",
            "  100   28 1668   14   31   23   27 7479   29  220  468    8  124   14\n",
            "  286  170    8  157   46    5   27  239   16  179    2   38   32   25\n",
            " 7944  451  202   14    6  717]\n",
            "Prediction: Negative\n",
            "Actual: Negative\n",
            "\n",
            "Review: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    1   14\n",
            "   22 3443    6  176    7 5063   88   12 2679   23 1310    5  109  943\n",
            "    4  114    9   55  606    5  111    7    4  139  193  273   23    4\n",
            "  172  270   11 7216    2    4 8463 2801  109 1603   21    4   22 3861\n",
            "    8    6 1193 1330   10   10    4  105  987   35  841    2   19  861\n",
            " 1074    5 1987    2   45   55  221   15  670 5304  526   14 1069    4\n",
            "  405    5 2438    7   27   85  108  131    4 5045 5304 3884  405    9\n",
            " 3523  133    5   50   13  104   51   66  166   14   22  157    9    4\n",
            "  530  239   34 8463 2801   45  407   31    7   41 3778  105   21   59\n",
            "  299   12   38  950    5 4521   15   45  629  488 2733  127    6   52\n",
            "  292   17    4 6936  185  132 1988 5304 1799  488 2693   47    6  392\n",
            "  173    4    2 4378  270 2352    4 1500    7    4   65   55   73   11\n",
            "  346   14   20    9    6  976 2078    7 5293  861    2    5 4182   30\n",
            " 3127    2   56    4  841    5  990  692    8    4 1669  398  229   10\n",
            "   10   13 2822  670 5304   14    9   31    7   27  111  108   15 2033\n",
            "   19 7836 1429  875  551   14   22    9 1193   21   45 4829    5   45\n",
            "  252    8    2    6  565  921 3639   39    4  529   48   25  181    8\n",
            "   67   35 1732   22   49  238   60  135 1162   14    9  290    4   58\n",
            "   10   10  472   45   55  878    8  169   11  374 5687   25  203   28\n",
            "    8  818   12  125    4 3077]\n",
            "Prediction: Positive\n",
            "Actual: Positive\n",
            "\n",
            "Review: [1239 5189  137    2   18   27  173    9 2399   17    6    2  428    2\n",
            "  232   11    4 8014   37  272   40 2708  247   30  656    6    2   54\n",
            "    2 3292   98    6 2840   40  558   37 6093   98    4    2 1197   15\n",
            "   14    9   57 4893    5 4659    6  275  711 7937    2 3292   98    6\n",
            "    2   10   10 6639   19   14    2  267  162  711   37 5900  752   98\n",
            "    4    2 2378   90   19    6    2    7    2 1810    2    4 4770 3183\n",
            "  930    8  508   90    4 1317    8    4    2   17    2 3965 1853    4\n",
            " 1494    8 4468  189    4    2 6287 5774    4 4770    5   95  271   23\n",
            "    6 7742 6063    2 5437   33 1526    6  425 3155    2 4535 1636    7\n",
            "    4 4669    2  469    4 4552   54    4  150 5664    2  280   53    2\n",
            "    2   18  339   29 1978   27 7885    5    2   68 1830   19 6571    2\n",
            "    4 1515    7  263   65 2132   34    6 5680 7489   43  159   29    9\n",
            " 4706    9  387   73  195  584   10   10 1069    4   58  810   54   14\n",
            " 6078  117   22   16   93    5 1069    4  192   15   12   16   93   34\n",
            "    6 1766    2   33    4 5673    7   15    2 9252 3286  325   12   62\n",
            "   30  776    8   67   14   17    6    2   44  148  687    2  203   42\n",
            "  203   24   28   69    2 6676   11  330   54   29   93    2   21  845\n",
            "    2   27 1099    7  819    4   22 1407   17    6    2  787    7 2460\n",
            "    2    2  100   30    4 3737 3617 3169 2321   42 1898   11    4 3814\n",
            "   42  101  704    7  101  999   15 1625   94 2926  180    5    9 9101\n",
            "   34    2   45    6 1429   22   60    6 1220   31   11   94 6408   96\n",
            "   21   94  749    9   57  975]\n",
            "Prediction: Negative\n",
            "Actual: Positive\n",
            "\n",
            "Review: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    1   13 1228  119   14  552    7\n",
            "   20  190   14   58   13  258  546 1786    8 1968    4  268  237   13\n",
            "  191   81   15   13   80   43 3824   44   12   14   16  427 3192    4\n",
            "  183   15  593   19    4  351  362   26   55  646   21    4 1239   84\n",
            "   26 1557 3755   13  244    6 2071  132  184  194    5   13   70 4478\n",
            "  546   73  190   13   62   24   81  320    4  538    4  117  250  127\n",
            "   11   14   20   82    4  452   11   14   20    9 8654   19   41  476\n",
            "    8    4  213    7 9185   13  657   13  286   38 1612   44   41    5\n",
            "   41 1729   88   13   62   28  900  510    4  509   51    6  612   59\n",
            "   16  193   61 4666    5  702  930  143  285   25   67   41   81  366\n",
            "    4  130   82    9  259  334  397 1195    7  149  102   15   26  814\n",
            "   38  465 1627   31   70  983   67   51    9  112  814   17   35  311\n",
            "   75   26    2  574   19    4 1729   23    4  268   38   95  138    4\n",
            "  609  191   75   28  314 1772]\n",
            "Prediction: Negative\n",
            "Actual: Negative\n",
            "\n",
            "Review: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    1   40   49   85\n",
            "   84 1040  146    6  783  254 4386  337    5   13  447   14  500   10\n",
            "   10   14  500  517 1076  357   21 1684   72   45  290   12   17  515\n",
            "   17   25  380  129 3305    4 2191   26  253    5    2   36   80 4357\n",
            "   25    2  129  330  505    8    2  146   24 3988   14  500    9   82\n",
            "    2    5    9 1293  224   10   10    8  401   14 1361  879   13   28\n",
            "    8  401   61 1642 2925   44 1373   21  591  353   14  500 4092   30\n",
            "  290   12   10   10   65  790  790  206  158  300   45   15   52    2\n",
            "  158  692    2  158  856  158]\n",
            "Prediction: Positive\n",
            "Actual: Positive\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the model architecture and weights as a single HDF5 file\n",
        "model.save('sentiment_analysis_model.h5')\n",
        "\n",
        "# Save the model architecture to JSON format\n",
        "model_json = model.to_json()\n",
        "\n",
        "# Save the architecture and weights to a pickle file\n",
        "with open('sentiment_analysis_model.pkl', 'wb') as file:\n",
        "    pickle.dump({'model_json': model_json, 'model_weights': model.get_weights()}, file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiZYiAKKFbQH",
        "outputId": "38a7f0ff-fea8-4d9d-ee10-a2ef1b875f2f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P_yORrmSFrK_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}